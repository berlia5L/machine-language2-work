{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f50146bdc0e1c28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T18:09:54.265350Z",
     "start_time": "2024-12-09T18:07:25.942808Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 检查 GPU 是否可用\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 数据加载与预处理\n",
    "transform = transforms.Compose([transforms.Resize((224, 224)),  # ResNet 要求输入尺寸\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "# 加载 CIFAR-10 数据集\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 加载预训练的 ResNet 模型\n",
    "resnet = torchvision.models.resnet18(pretrained=True)\n",
    "resnet.fc = nn.Identity()  # 去掉最后的分类层，保留特征提取部分\n",
    "resnet.to(device)  # 将模型移动到 GPU\n",
    "resnet.eval()\n",
    "\n",
    "# 提取特征函数\n",
    "def extract_features(loader, model, device):\n",
    "    features = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(loader, desc=\"Extracting features\"):  # tqdm 显示进度\n",
    "            images = images.to(device)  # 将输入数据移动到 GPU\n",
    "            outputs = model(images)  # 提取特征\n",
    "            features.append(outputs.cpu())  # 移动回 CPU\n",
    "            labels.append(targets)\n",
    "    features = torch.cat(features).numpy()\n",
    "    labels = torch.cat(labels).numpy()\n",
    "    return features, labels\n",
    "\n",
    "# 提取训练和测试集的特征\n",
    "print(\"Extracting features using ResNet on GPU...\")\n",
    "X_train, y_train = extract_features(train_loader, resnet, device)\n",
    "X_test, y_test = extract_features(test_loader, resnet, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69179907a7843de8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T18:14:48.138851Z",
     "start_time": "2024-12-09T18:13:47.832650Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 定义评估函数\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    return {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1': f1}\n",
    "\n",
    "# 保存指标的字典\n",
    "metrics = {}\n",
    "\n",
    "# 逻辑回归分类\n",
    "print(\"Training Logistic Regression...\")\n",
    "log_reg = LogisticRegression(max_iter=500, multi_class='multinomial', solver='lbfgs', random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "metrics['LogisticRegression'] = evaluate_model(log_reg, X_test, y_test)\n",
    "\n",
    "# LightGBM 分类\n",
    "print(\"Training LightGBM...\")\n",
    "lgb_train = lgb.Dataset(X_train, label=y_train)\n",
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 10,  # CIFAR-10 有 10 个类别\n",
    "    'boosting_type': 'gbdt',\n",
    "    'metric': 'multi_logloss',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.1,\n",
    "    'feature_fraction': 0.9,\n",
    "    'verbose': -1,\n",
    "    'random_state': 42\n",
    "}\n",
    "lgb_model = lgb.train(params, lgb_train, num_boost_round=100)\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "y_pred_lgb = y_pred_lgb.argmax(axis=1)  # 获取预测的类别\n",
    "metrics['LightGBM'] = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_lgb),\n",
    "    'precision': precision_score(y_test, y_pred_lgb, average='macro'),\n",
    "    'recall': recall_score(y_test, y_pred_lgb, average='macro'),\n",
    "    'f1': f1_score(y_test, y_pred_lgb, average='macro')\n",
    "}\n",
    "\n",
    "# 随机森林分类\n",
    "print(\"Training Random Forest...\")\n",
    "random_forest = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "metrics['RandomForest'] = evaluate_model(random_forest, X_test, y_test)\n",
    "\n",
    "# 打印保存的指标\n",
    "print(\"Metrics for all models:\")\n",
    "for model_name, model_metrics in metrics.items():\n",
    "    print(f\"{model_name}: {model_metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faed02b5b90cec24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T18:09:54.748772Z",
     "start_time": "2024-12-09T18:09:54.266346Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 可视化指标的高级柱状图\n",
    "def plot_metrics(metrics):\n",
    "    metrics_names = ['accuracy', 'precision', 'recall', 'f1']\n",
    "    model_names = list(metrics.keys())\n",
    "    \n",
    "    # 设置浅色系配色\n",
    "    colors = ['#ADD8E6', '#90EE90', '#FFB6C1', '#FFDAB9']\n",
    "    \n",
    "    for metric_name in metrics_names:\n",
    "        values = [metrics[model][metric_name] for model in model_names]\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        bars = plt.bar(model_names, values, color=colors, alpha=0.8, edgecolor='black')\n",
    "        \n",
    "        # 添加数值标注\n",
    "        for bar in bars:\n",
    "            yval = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, yval + 0.02, f\"{yval:.2f}\",\n",
    "                     ha='center', va='bottom', fontsize=12, color='black')\n",
    "        \n",
    "        # 美化图形\n",
    "        plt.title(f\"Comparison of {metric_name.capitalize()} Across Models\", fontsize=16, fontweight='bold')\n",
    "        plt.ylabel(metric_name.capitalize(), fontsize=14)\n",
    "        plt.xlabel(\"Models\", fontsize=14)\n",
    "        plt.ylim(0, 1)  # 设置 y 轴范围为 0 到 1\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        \n",
    "        # 保存或展示图像\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# 调用绘图函数\n",
    "plot_metrics(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb2844e5845bbb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T17:35:34.524853Z",
     "start_time": "2024-12-09T17:35:17.850789Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 使用 K-means 聚类\n",
    "print(\"Performing K-means clustering...\")\n",
    "kmeans = KMeans(n_clusters=10, random_state=42)\n",
    "kmeans_labels = kmeans.fit_predict(X_train)\n",
    "\n",
    "# 使用 PCA 将数据降至 2 维\n",
    "print(\"Reducing dimensions with PCA...\")\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_train)\n",
    "\n",
    "# 绘制聚类结果的散点图\n",
    "def plot_clusters(X, labels, title=\"K-means Clustering with PCA\"):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    \n",
    "    # 获取唯一的簇标签\n",
    "    unique_labels = np.unique(labels)\n",
    "    colors = plt.cm.Paired(np.linspace(0, 1, len(unique_labels)))  # 使用一组颜色\n",
    "    \n",
    "    for label, color in zip(unique_labels, colors):\n",
    "        cluster_points = X[labels == label]\n",
    "        plt.scatter(cluster_points[:, 0], cluster_points[:, 1], \n",
    "                    s=50, label=f\"Cluster {label}\", color=color, alpha=0.7, edgecolor='k')\n",
    "    \n",
    "    # 美化图形\n",
    "    plt.title(title, fontsize=16, fontweight='bold')\n",
    "    plt.xlabel(\"Principal Component 1\", fontsize=14)\n",
    "    plt.ylabel(\"Principal Component 2\", fontsize=14)\n",
    "    plt.legend(title=\"Clusters\", fontsize=10)\n",
    "    plt.grid(alpha=0.5, linestyle='--')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 调用函数绘制散点图\n",
    "plot_clusters(X_pca, kmeans_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ca3c22c00db950",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T18:13:19.521700Z",
     "start_time": "2024-12-09T18:13:18.561269Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 混淆矩阵和分类报告函数\n",
    "def evaluate_and_visualize(y_test, y_pred, model_name):\n",
    "    # 混淆矩阵\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"\\nClassification Report for {model_name}:\\n\")\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "    \n",
    "    # 可视化混淆矩阵\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\", xticklabels=range(10), yticklabels=range(10))\n",
    "    plt.title(f\"Confusion Matrix for {model_name}\", fontsize=16)\n",
    "    plt.xlabel(\"Predicted Labels\", fontsize=14)\n",
    "    plt.ylabel(\"True Labels\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# LG 混淆矩阵和分类报告\n",
    "print(\"Evaluating log...\")\n",
    "y_pred_knn = log_reg.predict(X_test)\n",
    "evaluate_and_visualize(y_test, y_pred_knn, \"log\")\n",
    "\n",
    "# LightGBM 混淆矩阵和分类报告\n",
    "print(\"Evaluating LightGBM...\")\n",
    "evaluate_and_visualize(y_test, y_pred_lgb, \"LightGBM\")\n",
    "\n",
    "# 随机森林 混淆矩阵和分类报告\n",
    "print(\"Evaluating Random Forest...\")\n",
    "y_pred_rf = random_forest.predict(X_test)\n",
    "evaluate_and_visualize(y_test, y_pred_rf, \"Random Forest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f12f6e8b501f2d7",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-09T18:14:55.926064Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 数据预处理：标准化\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Optuna 调参目标函数\n",
    "def objective(trial):\n",
    "    # 定义超参数搜索空间\n",
    "    penalty = trial.suggest_categorical('penalty', ['l2', 'none'])  # 正则化类型\n",
    "    C = trial.suggest_float('C', 0.01, 10.0, log=True)  # 正则化强度\n",
    "    max_iter = trial.suggest_int('max_iter', 500, 2000)  # 最大迭代次数\n",
    "\n",
    "    # 初始化逻辑回归模型\n",
    "    model = LogisticRegression(\n",
    "        penalty=penalty,\n",
    "        C=C,\n",
    "        max_iter=max_iter,\n",
    "        random_state=42,\n",
    "        solver='lbfgs',  # 支持多分类\n",
    "        multi_class='multinomial'\n",
    "    )\n",
    "    \n",
    "    # 训练模型\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # 验证集预测\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # 返回准确率作为优化目标\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "# 进行参数调优\n",
    "print(\"Starting Optuna parameter tuning...\")\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# 最佳参数和最佳准确率\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "print(\"\\nBest parameters found by Optuna:\")\n",
    "print(best_params)\n",
    "print(f\"Best accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "# 使用最佳参数重新训练逻辑回归\n",
    "print(\"Retraining Logistic Regression with best parameters...\")\n",
    "best_model = LogisticRegression(\n",
    "    penalty=best_params['penalty'],\n",
    "    C=best_params['C'],\n",
    "    max_iter=best_params['max_iter'],\n",
    "    random_state=42,\n",
    "    solver='lbfgs',\n",
    "    multi_class='multinomial'\n",
    ")\n",
    "best_model.fit(X_train_scaled, y_train)\n",
    "y_pred_best = best_model.predict(X_test_scaled)\n",
    "\n",
    "# 分类报告和混淆矩阵\n",
    "print(\"\\nBest Logistic Regression Classification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred_best, digits=4))\n",
    "\n",
    "# 混淆矩阵可视化\n",
    "def visualize_confusion_matrix(y_true, y_pred, model_name=\"Best Logistic Regression\"):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\", xticklabels=range(5), yticklabels=range(5))\n",
    "    plt.title(f\"Confusion Matrix for {model_name}\", fontsize=16)\n",
    "    plt.xlabel(\"Predicted Labels\", fontsize=14)\n",
    "    plt.ylabel(\"True Labels\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_confusion_matrix(y_test, y_pred_best, model_name=\"Best Logistic Regression\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfa08bbbaf13fa2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T18:04:12.391241Z",
     "start_time": "2024-12-09T18:04:07.798721Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# nltk 数据下载\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# 数据集加载\n",
    "def load_bbc_dataset(base_path):\n",
    "    texts, labels = [], []\n",
    "    label_map = {\"business\": 0, \"entertainment\": 1, \"politics\": 2, \"sport\": 3, \"tech\": 4}\n",
    "    for label, label_id in label_map.items():\n",
    "        folder = os.path.join(base_path, label)\n",
    "        for file in os.listdir(folder):\n",
    "            file_path = os.path.join(folder, file)\n",
    "            with open(file_path, 'r', encoding='latin1') as f:\n",
    "                texts.append(f.read())\n",
    "                labels.append(label_id)\n",
    "    return texts, labels\n",
    "\n",
    "# 数据预处理\n",
    "def preprocess_text(texts):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    preprocessed_texts = []\n",
    "    for text in texts:\n",
    "        # 转小写，移除标点\n",
    "        text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
    "        # 分词\n",
    "        words = word_tokenize(text)\n",
    "        # 移除停用词\n",
    "        words = [word for word in words if word not in stop_words]\n",
    "        preprocessed_texts.append(' '.join(words))\n",
    "    return preprocessed_texts\n",
    "\n",
    "# 自定义数据集类\n",
    "class BBCDataset(Dataset):\n",
    "    def __init__(self, texts, labels, vectorizer):\n",
    "        self.texts = vectorizer.transform(texts).toarray()\n",
    "        self.labels = np.array(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.texts[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "# 神经网络模型\n",
    "class TextClassificationModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_classes):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return self.softmax(x)\n",
    "\n",
    "# 加载数据\n",
    "base_path = \"./\"  # 替换为 BBC 数据集的根路径\n",
    "texts, labels = load_bbc_dataset(base_path)\n",
    "\n",
    "# 数据预处理\n",
    "texts = preprocess_text(texts)\n",
    "\n",
    "# 特征提取\n",
    "vectorizer = CountVectorizer(max_features=5000)  # 选择前 5000 个最常见词\n",
    "vectorizer.fit(texts)\n",
    "\n",
    "# 划分数据集\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 创建数据加载器\n",
    "train_dataset = BBCDataset(X_train, y_train, vectorizer)\n",
    "test_dataset = BBCDataset(X_test, y_test, vectorizer)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 模型训练\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TextClassificationModel(input_dim=5000, hidden_dim=128, num_classes=5).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 训练过程 (记录训练和测试集的损失)\n",
    "def train_model_with_loss(model, train_loader, test_loader, num_epochs=10):\n",
    "    train_losses, test_losses = [], []\n",
    "    train_accuracies, test_accuracies = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss, correct, total = 0, 0, 0\n",
    "\n",
    "        for texts, labels in train_loader:\n",
    "            texts, labels = texts.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(texts)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_loss = total_train_loss / len(train_loader)\n",
    "        train_accuracy = correct / total\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "\n",
    "        # 验证集损失和准确率\n",
    "        model.eval()\n",
    "        total_test_loss, correct, total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for texts, labels in test_loader:\n",
    "                texts, labels = texts.to(device), labels.to(device)\n",
    "                outputs = model(texts)\n",
    "                loss = criterion(outputs, labels)\n",
    "                total_test_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        test_loss = total_test_loss / len(test_loader)\n",
    "        test_accuracy = correct / total\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Train Acc: {train_accuracy:.4f}, Test Acc: {test_accuracy:.4f}\")\n",
    "\n",
    "    return train_losses, test_losses, train_accuracies, test_accuracies\n",
    "\n",
    "# 训练模型\n",
    "\n",
    "\n",
    "# 模型评估\n",
    "def evaluate_model(model, loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for texts, labels in loader:\n",
    "            texts, labels = texts.to(device), labels.to(device)\n",
    "            outputs = model(texts)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "# 训练模型\n",
    "num_epochs = 10\n",
    "train_losses, test_losses, train_accuracies, test_accuracies = train_model_with_loss(model, train_loader, test_loader, num_epochs)\n",
    "# 绘制损失曲线和准确率曲线\n",
    "def plot_metrics_with_test(train_losses, test_losses, train_accuracies, test_accuracies):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Loss 曲线\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label=\"Train Loss\", color='blue')\n",
    "    plt.plot(test_losses, label=\"Test Loss\", color='orange')\n",
    "    plt.title(\"Loss Curve\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.5)\n",
    "\n",
    "    # Accuracy 曲线\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accuracies, label=\"Train Accuracy\", color='green')\n",
    "    plt.plot(test_accuracies, label=\"Test Accuracy\", color='red')\n",
    "    plt.title(\"Accuracy Curve\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_metrics_with_test(train_losses, test_losses, train_accuracies, test_accuracies)\n",
    "\n",
    "# 混淆矩阵和分类报告\n",
    "def confusion_and_report(model, loader):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for texts, labels in loader:\n",
    "            texts, labels = texts.to(device), labels.to(device)\n",
    "            outputs = model(texts)\n",
    "            _, predicted = outputs.max(1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    print(\"\\nClassification Report:\\n\")\n",
    "    print(classification_report(all_labels, all_preds, digits=4, target_names=[\"business\", \"entertainment\", \"politics\", \"sport\", \"tech\"]))\n",
    "\n",
    "    # 混淆矩阵可视化\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\", xticklabels=[\"business\", \"entertainment\", \"politics\", \"sport\", \"tech\"], yticklabels=[\"business\", \"entertainment\", \"politics\", \"sport\", \"tech\"])\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted Labels\")\n",
    "    plt.ylabel(\"True Labels\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "confusion_and_report(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e735269210b2c28c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T18:07:08.104718Z",
     "start_time": "2024-12-09T18:06:53.021548Z"
    }
   },
   "outputs": [],
   "source": [
    "# 优化的神经网络模型\n",
    "class OptimizedTextClassificationModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, num_classes):\n",
    "        super(OptimizedTextClassificationModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim1)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim2)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc3 = nn.Linear(hidden_dim2, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        return self.softmax(x)\n",
    "\n",
    "# 初始化优化后的模型\n",
    "model = OptimizedTextClassificationModel(input_dim=5000, hidden_dim1=256, hidden_dim2=128, num_classes=5).to(device)\n",
    "\n",
    "# 优化器和学习率调度器\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)  # 每5个epoch学习率减半\n",
    "\n",
    "# 训练过程 (添加调度器)\n",
    "def train_model_with_scheduler(model, train_loader, test_loader, num_epochs=10):\n",
    "    train_losses, test_losses = [], []\n",
    "    train_accuracies, test_accuracies = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss, correct, total = 0, 0, 0\n",
    "\n",
    "        for texts, labels in train_loader:\n",
    "            texts, labels = texts.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(texts)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_loss = total_train_loss / len(train_loader)\n",
    "        train_accuracy = correct / total\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "\n",
    "        # 验证集损失和准确率\n",
    "        model.eval()\n",
    "        total_test_loss, correct, total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for texts, labels in test_loader:\n",
    "                texts, labels = texts.to(device), labels.to(device)\n",
    "                outputs = model(texts)\n",
    "                loss = criterion(outputs, labels)\n",
    "                total_test_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        test_loss = total_test_loss / len(test_loader)\n",
    "        test_accuracy = correct / total\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "\n",
    "        # 更新学习率\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Train Acc: {train_accuracy:.4f}, Test Acc: {test_accuracy:.4f}\")\n",
    "\n",
    "    return train_losses, test_losses, train_accuracies, test_accuracies\n",
    "\n",
    "# 训练优化后的模型\n",
    "print(\"Training optimized model...\")\n",
    "train_losses, test_losses, train_accuracies, test_accuracies = train_model_with_scheduler(model, train_loader, test_loader, 100)\n",
    "\n",
    "# 绘制损失曲线和准确率曲线\n",
    "plot_metrics_with_test(train_losses, test_losses, train_accuracies, test_accuracies)\n",
    "\n",
    "# 混淆矩阵和分类报告\n",
    "confusion_and_report(model, test_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
